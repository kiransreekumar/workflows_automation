variables:
  - group: 'Devops Automation'


trigger:
  branches:
    include:
    - main


stages:
- stage: 'Git_and_Dependencies'
  condition: |
    and(
      ne(variables['Build.SourceBranch'], 'refs/heads/releases'),
      not(startsWith(variables['Build.SourceBranch'], 'refs/tags/v'))
    )
  jobs:
  - job: 'onPushJob'
    pool:
      vmImage: 'ubuntu-20.04'

    steps:
    - script: |
        curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh
    - script: env | sort
      displayName: 'Environment / Context'
    - checkout: self
      persistCredentials: "true"
      clean: "true"
      displayName: 'Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)'


    - task: PublishPipelineArtifact@1
      inputs:
        targetPath: '$(Build.ArtifactStagingDirectory)'
        artifactName: Databricks
        artifactType: 'pipeline'
    
    - script: databricks fs cp $(Pipeline.Workspace)/Databricks/* dbfs:/Volumes/sales_dbt/sales_kiran_sreekumar/wheel --overwrite
      displayName: 'Copy to volumes'

- stage: 'Databricks_Asset_Bundles_Deployment'
  displayName: 'Deploying Bundles'
  jobs:
  - job: 'bundle_deploy'
    steps:

    - script: |
            databricks bundle deploy --var="warehouse_id=$(BUNDLE_VAR_warehouse_id),node_type=$(BUNDLE_VAR_node_type)"
      displayName: 'Deploying Bundles'

    




