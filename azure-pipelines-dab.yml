variables:
  - group: 'Devops Automation'


trigger:
  branches:
    include:
    - main
    - release

stages:
# Run BundleCI stage upon making a PR against the /ref/head/main branch 
- stage: BundleCI
  displayName: 'Bundle validation for workflows_automation'
  # Trigger BundleCI stage on PR against the default branch, and not on pushes to other branches
  condition: |
    and(
      not(eq(variables['Build.Reason'], 'IndividualCI')),
      eq(variables['Build.Reason'], 'PullRequest'),
      eq(variables['System.PullRequest.TargetBranch'], 'main')
    )



  jobs:
  - job: StagingBundleCI
    displayName: 'Staging bundle validation for workflows_automation'

    pool:
      vmImage: 'ubuntu-latest'

    steps:
    - script: env | sort
      displayName: 'Environment / Context'

    - checkout: self
      displayName: 'Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)'
      persistCredentials: true
      clean: true


    # Install Databricks CLI
    - script: |
        curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/v0.212.2/install.sh | sh   
      displayName: 'Install Databricks CLI'   

    - script: |
        pip install wheel
      displayName: 'Install wheel'


    # Validate bundle to be deployed to the staging workspace
    - script: |
        databricks bundle validate --var="warehouse_id=$(BUNDLE_VAR_warehouse_id),node_type=$(BUNDLE_VAR_node_type)" -t staging
      displayName: 'Validate bundle for staging'
      env:
        ARM_TENANT_ID: $(STAGING_AZURE_SP_TENANT_ID)
        ARM_CLIENT_ID: $(STAGING_AZURE_SP_APPLICATION_ID)
        ARM_CLIENT_SECRET: $(STAGING_AZURE_SP_CLIENT_SECRET)





  - job: prodBundleCI
    displayName: 'Prod bundle validation for workflows_automation'
    dependsOn: []   # Removes the implicit dependency on previous job and force prodBundleCI job to run in parallel

    steps:
    - script: env | sort
      displayName: 'Environment / Context'

    - checkout: self
      displayName: 'Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)'
      persistCredentials: true
      clean: true

    # Install Databricks CLI
    - script: |
        curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/v0.212.2/install.sh | sh   
      displayName: 'Install Databricks CLI'        

    - script: |
        pip install wheel
      displayName: 'Install wheel'  

    # Validate bundle to be deployed to the prod workspace
    - script: |
        databricks bundle validate --var="warehouse_id=$(BUNDLE_VAR_warehouse_id),node_type=$(BUNDLE_VAR_node_type)" -t prod
      displayName: 'Validate bundle for prod'
      env:
        ARM_TENANT_ID: $(PROD_AZURE_SP_TENANT_ID)
        ARM_CLIENT_ID: $(PROD_AZURE_SP_APPLICATION_ID)
        ARM_CLIENT_SECRET: $(PROD_AZURE_SP_CLIENT_SECRET)








# Run StagingBundleCD stage after successfully merging into the main branch
- stage: StagingBundleCD
  displayName: 'Staging bundle deployment for worklow_automation'
  # Trigger deployment of bundle resources when PRs are merged into the main branch
  condition: |
    and(
      eq(variables['Build.SourceBranch'], 'main'),
      not(eq(variables['Build.Reason'], 'PullRequest'))
    )

  jobs:
  - job: StagingBundleCD
    displayName: 'Bundle Deployment for workflow_automation Staging'

    pool:
      vmImage: 'ubuntu-latest'

    steps:
    - script: env | sort
      displayName: 'Environment / Context'

    - checkout: self
      displayName: 'Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)'
      persistCredentials: true
      clean: true

      # Install Databricks CLI
    - script: |
        curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/v0.212.2/install.sh | sh   
      displayName: 'Install Databricks CLI'          


    - script: |
        pip install wheel
      displayName: 'Install wheel'


    # Validate bundle to be deployed to the Staging workspace
    - script: |
        databricks bundle validate --var="warehouse_id=$(BUNDLE_VAR_warehouse_id),node_type=$(BUNDLE_VAR_node_type)" -t staging
      displayName: 'Validate bundle for staging'
      env:
        ARM_TENANT_ID: $(STAGING_AZURE_SP_TENANT_ID)
        ARM_CLIENT_ID: $(STAGING_AZURE_SP_APPLICATION_ID)
        ARM_CLIENT_SECRET: $(STAGING_AZURE_SP_CLIENT_SECRET)
        

    # Deploy bundle to Staging workspace
    - script: |
        databricks bundle deploy --var="warehouse_id=$(BUNDLE_VAR_warehouse_id),node_type=$(BUNDLE_VAR_node_type)" -t staging
      displayName: 'Deploy bundle to staging'
      env:
        ARM_TENANT_ID: $(STAGING_AZURE_SP_TENANT_ID)
        ARM_CLIENT_ID: $(STAGING_AZURE_SP_APPLICATION_ID)
        ARM_CLIENT_SECRET: $(STAGING_AZURE_SP_CLIENT_SECRET)

    - script: databricks fs cp $(Build.Repository.LocalPath)/dist/*.whl dbfs:/Volumes/wheel_catalog/wheel_schema/wheel_volume --overwrite
      displayName: 'Copy to volumes'


# Run prod bundle CD stage after successfully merging into the release branch
- stage: prodBundleCD
  displayName: 'Prod bundle deployment for workflows_automation'
  # Trigger deployment of Bundle resources when PRs are merged into the release branch
  condition: |
    and(
      eq(variables['Build.SourceBranch'], 'refs/heads/release'),
      not(eq(variables['Build.Reason'], 'PullRequest'))
    )

  jobs:
  - job: prodBundleCD
    displayName: 'Bundle deployment for workflows_automation prod'

    pool:
      vmImage: 'ubuntu-latest'

    steps:
    - script: env | sort
      displayName: 'Environment / Context'

    - checkout: self
      displayName: 'Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)'
      persistCredentials: true
      clean: true

      # Install Databricks CLI
    - script: |
        curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/v0.212.2/install.sh | sh   
      displayName: 'Install Databricks CLI'       

    - script: |
        pip install wheel
      displayName: 'Install wheel'   

    # Validate bundle to be deployed to the prod workspace
    - script: |
        databricks bundle validate --var="warehouse_id=$(BUNDLE_VAR_warehouse_id),node_type=$(BUNDLE_VAR_node_type)" -t prod
      workingDirectory: $(workingDirectory)
      displayName: 'Validate bundle for prod'
      env:
        ARM_TENANT_ID: $(PROD_AZURE_SP_TENANT_ID)
        ARM_CLIENT_ID: $(PROD_AZURE_SP_APPLICATION_ID)
        ARM_CLIENT_SECRET: $(PROD_AZURE_SP_CLIENT_SECRET)
        

    # Deploy bundle to prod workspace
    - script: |
        databricks bundle deploy --var="warehouse_id=$(BUNDLE_VAR_warehouse_id),node_type=$(BUNDLE_VAR_node_type)" -t prod
      workingDirectory: $(workingDirectory)
      displayName: 'Deploy bundle to prod'
      env:
        ARM_TENANT_ID: $(PROD_AZURE_SP_TENANT_ID)
        ARM_CLIENT_ID: $(PROD_AZURE_SP_APPLICATION_ID)
        ARM_CLIENT_SECRET: $(PROD_AZURE_SP_CLIENT_SECRET)

    - script: databricks fs cp $(Build.Repository.LocalPath)/dist/*.whl dbfs:/Volumes/wheel_catalog/wheel_schema/wheel_volume --overwrite
      displayName: 'Copy to volumes'

   

    




